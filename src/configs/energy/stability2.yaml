

seed: 42
base_dir: /home/a03-sgoel/FLaT


lm:
  pretrained_esm: facebook/esm2_t33_650M_UR50D

model:
  d_model: 1280 
  num_heads: 2
  dropout: 0.5
  num_layers: 4

optim:
  type: adamw
  lr: 3e-5
  lr_end: 1e-5
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.98
  power: 1


training:
  mode: resume  # train / test / resume
  n_layers: 4
  max_steps: 50000
  warmup_steps: 5000
  log_every_n_steps: 10
  num_sanity_val_steps: 2
  val_check_interval: 24
  enable_progress_bar: true
  grad_clip_val: 1.0
  accum_grad_batches: 2
  devices: [0]  # list of GPU IDs from 0-7

sampling:
  langevin:
    steps: 64
    noise_eps: 1e-3
    lr: 0.01
  decoding:
    steps: 64
    gamma: 10
    lr: 0.01
  

data:
  batch_size: 64
  max_seq_len: 1024
  train: ${base_dir}/data/stability/energy/train.csv
  test: ${base_dir}/data/stability/energy/test.csv
  val: ${base_dir}/data/stability/energy/val.csv


wandb:
  project: flat_stability_v2
  group: programmablebio
  name: unnormed_stable_energy_transformer_steps50k_lr3e-5_bsz64_layers4_heads2_drpt0.5_betas0.99-0.98 
  id: ${.name}_${seed}


checkpointing:
  save_every_n_steps: 2000
  save_dir: ${base_dir}/checkpoints/energy/${wandb.name}
  resume_ckpt_path: ${checkpointing.save_dir}/step=34000.ckpt
  best_ckpt_path: ${checkpointing.save_dir}/best_model.ckpt