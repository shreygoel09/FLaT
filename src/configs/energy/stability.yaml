

seed: 42
base_dir: /home/a03-sgoel/FLaT


lm:
  pretrained_esm: facebook/esm2_t33_650M_UR50D

model:
  d_model: 1280
  dropout: 0.5

optim:
  type: adamw
  lr: 1e-4
  lr_end: 1e-5
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.98
  power: 1


training:
  mode: resume  # train / test / resume
  n_layers: 4
  max_steps: 30000
  warmup_steps: 1500
  log_every_n_steps: 5
  num_sanity_val_steps: 2
  val_check_interval: 24
  enable_progress_bar: true
  grad_clip_val: 1.0
  accum_grad_batches: 2
  devices: [0]  # list of GPU IDs from 0-7

sampling:
  langevin:
    steps:
    noise_eps:
    lr:
  decoding:
    steps:
    lr:
  

data:
  batch_size: 64
  max_seq_len: 1024
  train: ${base_dir}/data/stability/energy/train.csv
  test: ${base_dir}/data/stability/energy/test.csv
  val: ${base_dir}/data/stability/energy/val.csv


wandb:
  project: flat_stability
  group: programmablebio
  name: redo_energy_stable_deep-mlp_steps30k_lr1e-4_bsz64_gradbtches2_betas0.99-0.98
  id: ${.name}_${seed}


checkpointing:
  save_every_n_steps: 2000
  save_dir: ${base_dir}/checkpoints/energy/${wandb.name}
  resume_ckpt_path: ${checkpointing.save_dir}/step=14160.ckpt
  best_ckpt_path: ${checkpointing.save_dir}/best_model.ckpt